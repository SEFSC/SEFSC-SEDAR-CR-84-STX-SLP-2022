---
title: "Model Diagnostics"
---

Model diagnostics aimed to follow the conceptual process described by @carvalho2021. Their approach includes evaluating goodness of fit, information sources and structure, prediction skill, convergence, and model plausibility. Although @carvalho2021 advise detours and additional model explorations when initial diagnostic tests fail, advanced diagnostics, such as likelihood profiles, retrospective, and jitter analyses, were conducted even when initial tests failed to comprehensively communicate the various model configurations explored to the extent possible.

## Convergence

Three approaches were used to check for model convergence. They were investigating for the presence of (1) bounded parameters, (2) high final gradients, and (3) a positive definite hessian. As described by @carvalho2021 checking for bounded parameters can indicate discrepancies with data or model structure. Additionally, small final gradients and a positive definite hessian can indicate that the objective function achieved good convergence.

The models presented in this report all had a positive definite Hessian, indicating that each reached a local minimum and a locally optimal fit. None of the models had parameters that were bounded, suggesting the optimization was not constrained by parameter limits. Finally, the parameter gradients in all models were small and well below 0.001, which is commonly used in the R4SS R package to identify large gradients (@tbl-parm).

{{< pagebreak >}}

## Correlation Analysis

High correlation among parameters can lead to flat response surfaces and poor model stability. By performing a correlation analysis, modeling assumptions that lead to inadequate configurations can be identified. Because of the highly parameterized nature of stock assessment models, some parameters are expected to be correlated (e.g., stock recruit parameters). However, many strongly correlated parameters (e.g., > 0.95) suggest reconsidering modeling assumptions and parameterization.

High correlations (> 0.95) were observed across nearly all m2 model variation (@tbl-corr). One particularly noteworthy correlation was between the estimates of initial fishing mortality (Initial F) and unfished recruitment (R0), which exceeded 0.99 in all models except for version v3_m2, where it was slightly lower but still substantial at -0.90.

In the initial default configurations of both the m1 and m2 model variations, the standard error on the initial equilibrium catch was fixed at a low value of 0.01. This tightly constrained the model to the input catch of 30 metric tons, effectively limiting flexibility in estimating the corresponding initial fishing mortality. To address this issue, the standard error was increased to 0.3, allowing the estimated initial catch to diverge from the fixed input value (@tbl-eqcatch). This adjustment reduced the overly strong correlation between Initial F and R0 by relaxing the constraint on initial fishing mortality. The effects of increasing the standard error beyond 0.3 are discussed further in the sensitivity analyses section.

All m2 and m3 model variations showed moderately high correlations (\> 0.90) between the two parameters used to define the commercial fleet logistic selectivity: the size at peak selectivity and the width of the ascending limb. Correlations between these selectivity parameters are expected. While estimated values varied slightly among models, they produced similar size-based selectivity curves for the commercial fleet (@fig-m3-selectivity).

## Evaluating Variance

To check for parameters with high variance,  parameter estimates are reported with their resulting standard deviations. @tbl-parm presents the model-estimated values and standard deviations for the main active parameters. While it’s important to consider the scale of each parameter, the results suggest that key parameters are not being estimated with high precision. In particular, the coefficients of variation for initial fishing mortality are relatively high across all models, indicating considerable uncertainty in these estimates. 

@fig-m3-density illustrates how the estimate and uncertainty for the unfished recruitment (R0) and virgin spawning stock biomass change throughout the sequential steps of model development. Generally increasing the complexity of the model across the model variations explored results in lower values for both of these parameters. The uncertainty across the response surface for key parameters are further examined later in the report using likelihood profiles.

Stock Synthesis also provides estimates and standard deviations for derived quantities such as unfished spawning stock biomass, initial year spawning biomass, and the initial depletion as the initial biomass divided by the unfished biomass. @tbl-dq shows this information and it is also plotted in @fig-m3-ratio and @fig-m3-ssb.  

Compared to the other m3 model variations, Model v3_m2 had extremely highest uncertainty for fishing mortality and the lowest initial depletion reflected as the spawning biomass ratio (SSB Initial/SSB Unfished) (@table-dp; @fig-m3-f). All of the m3 model variations resulted in relatively high uncertainty and limited contrast, with most years encompassing the 95% confidence intervals across the entire time series (@fig-m3-dq). The sensitivity runs described later build on the exploration of uncertainty in these model variations and help interpret conditions under which all of the model variations increasingly converge.


## Jitter Analysis
Jitter analysis is a relatively simple method that can be used to assess model stability and to determine whether the search algorithm has found a global, as opposed to local, solution. The premise is that all starting values are randomly altered (or ‘jittered’) by an input constant value, and the model is rerun from the new starting values. If the resulting population trajectories across many runs converge to the same solution, this provides reasonable support that a global minimum has been obtained. This process is not fault-proof; no guarantee can ever be made that the ‘true’ solution has been found or that the model does not contain misspecification. However, if the jitter analysis results are consistent, it provides additional support that the model is performing well and has come to a stable solution. For this assessment, a jitter value of 0.2 was applied to the starting values, and 30 runs were completed. The jitter value defines a uniform distribution in cumulative normal space to generate new initial parameter values [@methot2020].

Consistent with earlier results indicating that the models reached local minima (positive definite Hessian), the jitter analysis also performed well across all model scenarios (@fig-jitter). Importantly, no jitter runs produced a lower likelihood than the best fit already identified for each model.

## Residual Analysis 

The primary approach to address performance was a residual analysis of model fit to each data set (e.g., catch, length compositions, indices). Any temporal trend in model residuals or disproportionately high residual values can indicate model misspecification and poor performance. Ideally, residuals are randomly distributed, conform to the assumed error structure for that data source, and are not of extreme magnitude. Any extreme positive or negative residual patterns indicate poor model performance and potential unaccounted-for process or observation error.

### Catch

All models nearly exactly matched the observed 2012 - 2022 catch data, which was expected given the data-limited configurations used. These setups don’t provide much additional information beyond the catch itself, so the model has little room to estimate catch values that differ from the input data. The effect of increasing the standard error on catch to 0.3 during the model development m3 variation was to give the model more flexibility in estimating initial equilibrium catch and corresponding initial fishing mortality. This adjustment allowed the model to explore alternative fits while still remaining informed by the assumption of a larger level of historically sustained catch. Increasing the standard error from 0.01 to 0.3 resulted in lower estimates of the initial equilibrium catch (@tbl-eqcatch). This topic will  be revisited in the sensitivity analyses, where model runs with even higher catch standard error of 2 are compared. Additional justifications for further allowing the estimated initial equilibrium catch to differ from the assumed initial equilibrium catch of 30 metric tons will also be noted with regard to the results of the likelihood profile for the equilibrium catch. 

### Indices
For the models without recruitment deviation being estimated (model variations b_m2, and v1_m2), the predicted National Coral Reef Monitoring Program index is flat (@fig-cpue). In the model variations with estimated recruitment deviations (v3_m3 and v7_m3), there is some improved fit to the index, whereby the slightly improved fits. Notably, the error rate was higher in 2014 and 2015, and none of models fit well to the highest value observed in 2015 (@fig-cpue).

### Length compositions

@fig-lenfit shows the cumulative fit across all years between the observed and predicted length composition for the two model variations had aggregated size data (a_m3 and v3_m3). @fig-lenfit-b, @fig-lenfit-v1, and @fig-lenfit-v7 provide the cumulative and the year specific length compositions for the model variations that included annual fishery-independent size data (b_m3, v1_m3, and v7_m3).

Among the models with the annual fishery-independent size data (b_m3, v1_m3, and v7_m3), the model with recruitment deviation being estimated (v7_m2), has improved fits to the annual National Coral Reef Monitoring Program length composition data (@fig-lenfit-v7-2). In the scenarios without recruitment deviations (b_m3 and v_m3), the predicted composition is identical across years, which leads to overestimating the proportion of the smallest size and underestimating intermediate or large sizes in 2012, 2017, and 2021 (@fig-lenfit-b-2 and @fig-lenfit-v1-2). This is also evident in @fig-meanlen where the observed and predicted mean length by year are plotted. 

## Retrospective Analysis

A retrospective analysis is a helpful approach for addressing the consistency of terminal year model estimates (e.g., SSB, Recruits, Fs) and is often considered a sensitivity exploration of impacts on key parameters from changes in data. The analysis sequentially removes a year of data and reruns the model. Suppose the resulting estimates of derived quantities such as SSB or recruitment differ significantly. In such a case, serial over- or underestimation of important quantities can indicate that the model has unidentified process error and could require reassessing model assumptions. It is expected that removing data will lead to slight differences between the new terminal year estimates and the estimates for that year in the model with the complete data. Estimates in years before the terminal year may have increasingly reliable information on cohort strength. Therefore, slight differences are usually expected between model runs as more years of size composition data are sequentially removed. Ideally, the difference in estimates will be slight and randomly distributed above and below the estimates from the model with the complete data sets. 

The results of a five-year retrospective analysis are plotted in @fig-retro. When more than 3 years are removed, the estimates of key quantities change. The sensitivity of the results to the removal of 2019 and 2018 data, is likely the result truncating the fishery-independent National Coral Reef Monitoring program index to end in 2017, corresponding with the highest observed value (@fig-cpue). Although all retrospectives show wide 95% confidence intervals, the severity of the retrospective pattern was most severe in the scenario with recruitment deviations and annual fishery dependent size data, variation v7_m2.

## Likelihood Profiles

Profile likelihoods are used to examine the change in negative log-likelihood for each data source to address the stability of a given parameter estimate and to see how each data source influences the estimate. The analysis is performed by holding a given parameter at a constant value and rerunning the model. The model is run repeatedly over a range of reasonable parameter values. Ideally, the graph of change in likelihood values against parameter values will yield a well-defined minimum. When the profile plot shows conflicting signals or is flat across its range, the given parameter may be poorly estimated.

Typically, profiling is carried out for key parameters, particularly those defining the stock-recruit relationship (steepness, virgin recruitment, and sigma R). Profiles were explored across virgin recruitment (R0), initial equilibrium catch, and steepness.

### Unfished Recruitment (R0)
@fig-profile-r0 shows the profile likelihood for the natural log of the unfished recruitment parameter of the Beverton – Holt stock-recruit function for St. Croix stoplight parrotfish across model variations (a_m3, b_m3, v1_m3, v3_m3, and v7_m3). All models show conflicting signals and relatively poorly-defined minimums, with a range of equally plausible values reflected by only small changes in likelihood. @fig-profile-r0-msyspr shows the corresponding change in the MSY SPR 40% across the range of unfished recruitment values explored. 

### Initial Equilibrium Catch
@fig-profile-eqcatch  shows the profile likelihood for the initial equilibrium catch for St. Croix stoplight parrotfish across model variations (a_m3, b_m3, v1_m3, v3_m3, and v7_m3). With the exception of model variation v3_m3, the models suggest improved fit associated with smaller values of fixed initial equilibrium catch. Meanwhile, v3_m3 shows a minimum around 24 metric tons, but is flat given the very small changes in the likelihoods across the range of values explored.  @fig-profile-eqcatch-msyspr shows the corresponding change in the MSY SPR 40% across the range of initial equilibrium catch values explored. This suggest that given further flexibility the initial equilibrium may be estimated lower and will be revisited in regard to the sensitivity runs.

### Steepness
@fig-profile-k shows the profile likelihood for steepness parameter of the Beverton – Holt
stock-recruit function for St. Croix stoplight parrotfish across model variations (a_m3, b_m3, v1_m3, v3_m3, and v7_m3). With the exception of a_m3, all models show lower likelihoods associated with higher values of steepness, driven by the fit to the length data. @@fig-profile-k-msyspr shows the corresponding change in the MSY SPR 40% across the range of steepness values explored. 


## Sensitivity Runs

Sensitivity analyses were considered to evaluate the impact on key derived quantities. The process and naming conventions can be reviewed in @tbl-ss3-stxslp. Sensitivities included considering alternatives for the CV on growth, the maximum age, the method used to model hermaphroditism, and the standard error associated with catch.

For each model variation and sensitivity run:
-   @tbl-eqcatch provides the initial equilibrium catch
-   @tbl-est-msy and @tbl-msy provide the MSY proxy (based on SPR 40%)
-   @tbl-msra summarizes the fishing mortality rate and spawning stock biomass ratios relative to the rate and biomass of the stock associated with the MSY proxy (based on SPR 40%)

### Growth CV
In the s1 sensitivity runs, the assumed CV for young fish of 0.15 was increased to 0.25. This did not have a meaningful change on the resulting derived quantities compared to the corresponding m3 model variations.

### Natural Mortality
The s2 sensitivity run explored a lower natural mortality of 0.18, corresponding to a higher maximum age of 30 years. Compared to the m3 model variations, this resulted in lower initial equilibrium catch, MSY estimates, and spawning stock biomass ratios, and higher fishing mortality relative ratios.

### Single Sex Model
The s3 sensitivity explored the second method for parameterizing hermaphroditism. It involved using a female-only model and accounting for sex transition to males as a reduction in fecundity. This did not have a meaningful change on the resulting derived quantities compared to the corresponding m3 model variations.

### Standard Error on Catch


### Standard Error on Catch, and Natural Mortality

### Single Sex Model, Standard Error on Catch, and Natural Mortality

